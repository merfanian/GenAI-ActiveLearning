import sys
import os
import pandas as pd

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..")))

import json
import logging
from pathlib import Path

from dotenv import load_dotenv

load_dotenv("/home/mahdi/Projects/GenAI-ActiveLearning/.env")

from services import (
    data_service,
    model_service,
    fairness_service,
)
from utils.attribute_mappings import (
    ADIENCE_GENDER_MAPPING,
    ADIENCE_GENDER_TARGET,
    UTKFACE_RACE_MAPPING,
    UTKFACE_RACE_TARGET,
    FRUITS_LABEL_MAPPING,
    FRUITS_LABEL_TARGET,
    FFHQ_GENDER_MAPPING,
    FFHQ_GENDER_TARGET,
    ANIMALS_LABEL_MAPPING,
    ANIMALS_LABEL_TARGET,
)

# --- Configuration ---
RESULTS_DIR = Path(
    "/home/mahdi/Projects/GenAI-ActiveLearning/experiments/exp_1.1_fairness_improvement/results"
)
ARCHITECTURE = "resnet"  # Assuming the original experiment used resnet as the main arch

BENCHMARKS = [
    {
        "name": "adience",
        "image_dir_path": "/home/mahdi/Projects/GenAI-ActiveLearning/resources/adience/",
        "metadata_csv_path": "/home/mahdi/Projects/GenAI-ActiveLearning/resources/adience/metadata_with_ethnicity_1500.csv",
        "target_attribute": "label",
        "fairness_attribute": "ethnicity",
    },
    {
        "name": "fruits",
        "image_dir_path": "/home/mahdi/Projects/GenAI-ActiveLearning/resources/fruits/dataset/",
        "metadata_csv_path": "/home/mahdi/Projects/GenAI-ActiveLearning/resources/fruits/filtered.csv",
        "target_attribute": "label",
        "fairness_attribute": "label",
    },
    {
        "name": "animals",
        "image_dir_path": "/home/mahdi/Projects/GenAI-ActiveLearning/resources/animals",
        "metadata_csv_path": "/home/mahdi/Projects/GenAI-ActiveLearning/resources/animals/metadata_4000.csv",
        "target_attribute": "label",
        "fairness_attribute": "label",
    },
    {
        "name": "ffhq",
        "image_dir_path": "/home/mahdi/Projects/GenAI-ActiveLearning/resources/ffhq/images/",
        "metadata_csv_path": "/home/mahdi/Projects/GenAI-ActiveLearning/resources/ffhq/metadata_with_ethnicity_2000.csv",
        "target_attribute": "gender",
        "fairness_attribute": "ethnicity",
    },
]

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def backfill_run(result_file_path: Path):
    logger.info(f"Processing {result_file_path}...")
    with open(result_file_path, "r") as f:
        results = json.load(f)

    if "groupdro_worst" in results:
        logger.info(f"GroupDRO results already exist. Skipping.")
        return

    benchmark_name = results["benchmark_name"]
    run_number = results["run"]

    config = next((b for b in BENCHMARKS if b["name"] == benchmark_name), None)
    if not config:
        logger.error(f"Could not find benchmark config for {benchmark_name}")
        return

    # Load dataset
    data_service.load_and_validate_dataset(
        config["image_dir_path"],
        config["metadata_csv_path"],
        config["target_attribute"],
        config["fairness_attribute"],
    )
    
    train_paths, train_labels, train_groups = data_service.get_train_val_image_paths_and_labels(
        include_augmented=False, fairness_attribute=config["fairness_attribute"]
    )
    test_df = data_service.get_test_metadata_df()
    test_paths, test_labels = data_service.get_test_image_paths_and_labels()

    # Train GroupDRO model
    logger.info("Training GroupDRO model...")
    groupdro_model_path = model_service.train_model(
        train_paths,
        train_labels,
        groups=train_groups,
        architecture=ARCHITECTURE,
        updated_model_path=f"backfill_{benchmark_name}_run_{run_number}_groupdro.pth",
        use_group_dro=True,
    )

    # Evaluate model
    logger.info("Evaluating GroupDRO model...")
    groupdro_gp_raw = fairness_service.calculate_group_performances(
        groupdro_model_path,
        test_df,
        test_paths,
        test_labels,
        config["fairness_attribute"],
    )
    groupdro_worst_raw = fairness_service.find_worst_performing_group(groupdro_gp_raw)
    groupdro_worst = groupdro_worst_raw.get("accuracy", 0.0)
    groupdro_overall = fairness_service.calculate_overall_accuracy(
        groupdro_model_path, test_paths, test_labels
    )
    
    logger.info(f"GroupDRO Results: Worst-Group={groupdro_worst:.4f}, Overall={groupdro_overall:.4f}")

    # Update and save results
    results["groupdro_worst"] = groupdro_worst
    results["groupdro_overall"] = groupdro_overall

    with open(result_file_path, "w") as f:
        json.dump(results, f, indent=4)
    logger.info(f"Successfully updated {result_file_path} with GroupDRO results.")


def main():
    # Look for the specific comparison results files generated by the previous script
    for result_file in RESULTS_DIR.glob("*_results.json"):
        backfill_run(result_file)

if __name__ == "__main__":
    main()
